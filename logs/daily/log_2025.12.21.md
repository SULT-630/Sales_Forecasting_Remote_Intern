# Daily Log — 2025-12-19

## Objective
- Create Evaluation Framework
- Fit into raw data and XGB model
- Check index and plot figures to evaluate and compare between different results
- Improve on the accuracy using feature engineering and results from data cleaning

## Work Done
- Create framework for running model and evaluation
- adjust evaluator to use k-fold methods
- Run the framwork on the raw data without week
- Run the framwork on the raw data without week but with discount
- Run the framwork on the raw data without week but with discount and log transformation

## Key Findings
- 原始数据集去除week特征之后的预测：[RMSE，MAE,R2] = 训练: [16.94,10.72, 0.92]; 测试: [24.36，12.79，0.82]
    - 平均每个预测相差13个单位，RMSE比MAE 明显大，说明存在大误差样本，完全意料之中，因为直接去除了时序特征， R2分还可以，存在一些过拟合问题，可以作为baseline
    - 采取K-fold之后[RMSE，MAE,R2] = 训练: [16.94,10.72, 0.92]; 测试: [24.36，12.79，0.82]
- 原始数据集去除week特征,加上is_discount_sku, discount_ratio之后的预测：[RMSE，MAE,R2] = 训练: [16.94,10.72, 0.92]; 测试: [24.28, 12.81, 0.82]
    - 折扣带来的收益比较小，说明模型已经能够隐式地学习到折扣的信息
    - 采取K-fold之后：
        - mean: [RMSE，MAE,R2] = 训练: [16.71，10.64，0.9228]; 测试: [25.94，13.06，0.81]
        - std: [RMSE，MAE,R2] = 训练: [0.1664,0.0414,0.000756]; 测试: [1.1511,0.1386,0.006810]
- 原始数据去除week，units_sold 用log_sales代替,加上is_discount_sku, discount_ratio之后的预测： [RMSE，MAE,R2] = 训练: [20.93,11.36,0.88]; 测试: [24.16,12.66,0.82]
    - 整体表现比不做log变换更好，而且过拟合问题显著下降
## Issues Encountered
- train-test-split本身存在运气问题
## How Issues Were Resolved
- 使用K-fold来衡量
## Problems
- 之后要对df排序再训练的时候可能会导致eval的时候index对不上
## Next Steps